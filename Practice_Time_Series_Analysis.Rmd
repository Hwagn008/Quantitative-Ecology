---
title: "Workshop 3_Timeseries Models"
author: "Sparkle L. Malone"
date: "1/24/2020"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Objectives
The primary objectives of this analysis is ...

# Methods

load("/Users/helen/Documents/EcologyRWorkshop/Time_Series_Analysis/Github/ARIMA_Workshop.RData")

library(zoo)
library(tseries)
library(forecast)
library(xts)
library(fracdiff)

#### Part 1:
##### 1. Create timeseries objects:

In the frequency parameter in the ts() object, we are specifying periodicity of the data, i.e.,

nee <- ts( mangroves$nee, start= 1, frequency=30)

##### Visualize data:

A good starting point is to plot the timeseries and visually examine it for any outliers, volatility, or
irregularities.

par(mfrow=c(1,1), mai=c(1.25,0.8,0.1, 0.1))
plot( nee, typ="l", ylab= "NEE", xlab="")

You want to remove any outliers that could bias the model by skewing statistical summaries. R provides a convenient method for removing time series outliers: tsclean() as part of its forecast package. tsclean() identifies and replaces outliers using series smoothing and decomposition.

plot(nee)
lines(tsclean(nee), col="red")

nee <- tsclean(nee)

#### 2. Decompose the timeseries:

Time series analysis involves trying to separate the time series into the seasonal, trend and irregular components. Deconstructing the series will help you understand its behavior and prepare a foundation for building an
ARIMA model. The Seasonal component refers to fluctuations in the data related to calendar cycles. Usually, seasonality is fixed at some number; for instance, quarter or month of the year.Trend component is the overall pattern of the series. It consists of decreasing or increasing patterns that are not seasonal. This is estimated using moving averages.
The part of the series that can’t be attributed to the seasonal or trend components is referred to as residual or error.

nee.d <- decompose(nee, 'multiplicative')
plot(nee.d)

#### 3.a. Test for stationarity
Fitting an ARIMA model requires the series to be stationary. A series is stationary when its mean, variance, and autocovariance are time invariant. This assumption makes intuitive sense: Since ARIMA uses previous lags of series to model its behavior, modeling stable series with consistent properties involves less uncertainty. The augmented Dickey-Fuller (ADF) test is a formal statistical test for stationarity. The null hypothesis assumes that the series is non-stationary. ADF procedure tests whether the change in Y can be explained by
lagged value and a linear trend. If contribution of the lagged value to the change in Y is non-significant and there is a presence of a trend component, the series is non-stationary and null hypothesis will not be rejected.

##### p-value < 0.05 indicates the TS is stationary
adf.test(nee)

#### 3.b. Detecting Autocorrelation:

Autocorrelation plots (also known as ACF or the auto correlation function) are a useful visual tool in determining whether a series is stationary. ACF plots display correlation between a series and its lags.
If the series is correlated with its lags then, generally, there are some trend or seasonal components and therefore its statistical properties are not constant over time. ACF plots can help in determining the order of the MA (q) model. Partial autocorrelation plots (PACF), display correlation between a variable and its lags that is not explained by previous lags. PACF plots are useful when determining the order of the AR(p) model. R plots 95% significance boundaries as blue dotted lines.

acf(nee, lag.max=45)

pacf(nee, lag.max=45)

#### 4. Fitting an ARIMA Model:
Now let’s fit a model. The forecast package allows the user to explicitly specify the order of the model using the arima() function, or automatically generate a set of optimal (p, d, q) using auto.arima(). This function searches through combinations of order parameters and picks the set that optimizes model fit criteria. While auto.arima() can be very useful, it is still important to complete the steps above in order to understand the series and interpret model results.

arima.nee1 <-auto.arima(nee, trace=TRUE)

tsdisplay(residuals(arima.nee1), lag.max=45)

arima.nee2 <-arima(nee , order=c(10,1,3), seasonal= list(order=c(2,0,2)))

tsdisplay(residuals(arima.nee2), lag.max= 30)

##### You want to minimize AIC
AIC(arima.nee1, arima.nee2)

par(mfrow=c(1,1))
plot(nee , typ="l"); lines(fitted(arima.nee2),col="red")

##### Measuring for significant difference from white noise.
##### You need a p-value greater than 0.05!
checkresiduals(arima.nee2, lag=36)

par(mfrow=c(1,1))
plot(nee , typ="l"); lines(fitted(arima.nee2),col="red")

plot(forecast(arima.nee2, h=30))


## Site Information 

## Statistical Analysis

# Results (minimum of 1 plot and one table)

# Discussion (1 paragrapgh)
